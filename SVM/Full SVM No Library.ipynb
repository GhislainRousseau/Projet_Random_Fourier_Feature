{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### On crée notre noyau (ici gaussien)",
   "id": "880633dc9733fc41"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def rbf_kernel(x1, x2, gamma=2):\n",
    "    d = np.linalg.norm(x1-x2)\n",
    "    return np.exp((d**2)/(-gamma))"
   ],
   "id": "98c6438ccf821b99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### On crée la classe BinarySVM. C'est un classifieur binaire SVM, qui sera utilisé pour construire notre classifeur mutliclasse par stratégie One-VS-Rest.\n",
    "On veut pour entraîner notre classifieur trouver\n",
    "$\\max_{\\boldsymbol{\\mu}\\in\\mathbb{R}^n} \\sum_{i=1}^n\\mu_i\n",
    "-\\frac{1}{4\\lambda} \\sum_{i,j=1}^n y_iy_j\\mu_i\\mu_j K(x_i,x_j)$ afin d'obtenir les $\\alpha_i$ pour avoir notre estimateur $\\hat f(x)=\\sum\\limits_{i=1}^n\\alpha_iK(x_i,x)$.\n",
    "On procède par montée de gradient pour trouver le maximum.\n",
    "\n",
    "\n",
    "De plus on ajoute un biais $b$ de sorte que $\\hat f(x)=\\sum\\limits_{i=1}^n\\alpha_iK(x_i,x) + b$.\n",
    "\n",
    "\n",
    "On l'estime a posteriori donc c'est un peu approximatif mais beaucoup plus simple."
   ],
   "id": "f5d1e57f780b5b61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class BinarySVM:\n",
    "    def __init__(self, gamma=2, lr=0.001, n_iter=1000):\n",
    "        self.gamma = gamma\n",
    "        self.lr = lr\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def fit(self, X, y): #initialisation\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        n = X.shape[0]\n",
    "        self.alpha = np.zeros(n)\n",
    "\n",
    "        # on crée notre matrice de Gram\n",
    "        K = np.zeros((n, n)) #changer pour np.empty? -> Mémoire\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                K[i, j] = y[i]*y[j]*rbf_kernel(X[i],X[j],self.gamma)\n",
    "\n",
    "        # montée de gradient\n",
    "        for p in range(self.n_iter):\n",
    "            grad = 1 - np.dot(K, self.alpha)\n",
    "            self.alpha += self.lr * grad\n",
    "            self.alpha = np.clip(self.alpha,0,1/n)\n",
    "\n",
    "        # calcul du biais b\n",
    "        sv = (self.alpha > 1e-5)\n",
    "        self.b = np.mean([y[i] - np.sum(self.alpha*y*np.array([rbf_kernel(X[i],X[j],self.gamma) for j in range(n)])) for i in range(n) if sv[i]])\n",
    "\n",
    "    def decision(self, X):\n",
    "        scores = []\n",
    "        for x in X:\n",
    "            s = np.sum(self.alpha*self.y*np.array([rbf_kernel(x,xi,self.gamma) for xi in self.X]))\n",
    "            scores.append(s+self.b)\n",
    "        return np.array(scores)\n",
    "\n",
    "    def predict(self,X):\n",
    "        return np.sign(self.decision(X))\n"
   ],
   "id": "49fbfde73714fd31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SVM_OVR:\n",
    "    def __init__(self, gamma=2):\n",
    "        self.gamma = gamma\n",
    "        self.models = {} #dico des modèles pour chaque classe\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y) #on récupère le nombre de classes = nombres d'estimateurs (OVR)\n",
    "        for c in self.classes:\n",
    "            y_binary = np.where(y == c,1,-1)\n",
    "            svm = BinarySVM(gamma=self.gamma)\n",
    "            svm.fit(X,y_binary)\n",
    "            self.models[c] = svm\n",
    "\n",
    "    def predict(self, X):\n",
    "        scores = np.column_stack([self.models[c].decision_function(X) for c in self.classes])\n",
    "        return self.classes[np.argmax(scores, axis=1)]\n"
   ],
   "id": "891b9d010e6a74ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Ici on affiche le plan dans lequel se trouvent les features pour représenter les frontières de décisions (et donc comment notre modèle découpe l'espace)",
   "id": "39aa640a81718052"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_decision_boundary(X, y, model):\n",
    "    h = 0.02\n",
    "    x_min,x_max=X[:,0].min()-1,X[:,0].max()+1\n",
    "    y_min,y_max=X[:,1].min()-1,X[:,1].max()+1\n",
    "\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
    "\n",
    "    Z = model.predict(np.c_[xx.ravel(),yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx,yy,Z,alpha=0.8)\n",
    "    plt.scatter(X[:,0],X[:,1],c=y,edgecolors='k')\n",
    "    plt.xlabel(\"Sepal length\")\n",
    "    plt.ylabel(\"Sepal width\")\n",
    "    plt.title(\"SVM à noyau RBF\")\n",
    "    plt.show()"
   ],
   "id": "cb65e2777b1e996f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:,:2]\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)\n",
    "\n",
    "svm = SVM_OVR(gamma=2)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "plot_decision_boundary(X_train,y_train,svm)\n"
   ],
   "id": "31878d12a207eb3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d0b6b63852d50875",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
